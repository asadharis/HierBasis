% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hier_basis.R
\name{HierBasis}
\alias{HierBasis}
\title{Nonparametric Regression using Hierarchical Basis Functions}
\usage{
HierBasis(x, y, nbasis = length(y), max.lambda = NULL, nlam = 50,
  lam.min.ratio = 1e-04, m.const = 3, type = c("gaussian", "binomial"),
  max.iter = 100, tol = 0.001, max.iter.inner = 100, tol.inner = 0.001)
}
\arguments{
\item{x}{A vector of dependent variables.}

\item{y}{A vector of response values we wish to fit the function to.}

\item{nbasis}{The number of basis functions. Default is length(y).}

\item{max.lambda}{The maximum lambda value for the penalized regression
problem. If \code{NULL} (default), then the function selects a maximum
lambda value such that the fitted function is the trivial estimate, i.e.
the mean of \code{y}.}

\item{nlam}{Number of lambda values for fitting penalized regression.
The functions uses a sequence of \code{nlam} lambda values on the log-scale
rangeing from \code{max.lambda} to \code{max.lambda * lam.min.ratio}.}

\item{lam.min.ratio}{The ratio of the largest and smallest lambda value.}

\item{m.const}{The order of smoothness, usually not more than 3 (default).}

\item{type}{Specifies type of regression, "gaussian" is for linear regression with continous
response and "binomial" is for logistic regression with binary response.}

\item{max.iter}{Maximum number of iterations for outer loop for
logistic regression.}

\item{tol}{Tolerance for convergence of outer loop.}

\item{max.iter.inner}{Maximum number of iterations for inner loop for
logistic regression.}

\item{tol.inner}{Tolerance for convergence of inner loop.}
}
\value{
An object of class HierBasis with the following elements:

\item{beta}{The \code{nbasis * nlam} matrix of estimated beta vectors.}
\item{intercept}{The vector of size \code{nlam} of estimated intercepts.}
\item{fitted.values}{The \code{nbasis * nlam} matrix of fitted values.}
\item{lambdas}{The sequence of lambda values used for
fitting the different models.}
\item{x, y}{The original \code{x} and \code{y} values used for estimation.}
\item{m.const}{The \code{m.const} value used for defining 'order' of smoothness.}
\item{nbasis}{The maximum number of basis functions we
allowed the method to fit.}
\item{active}{The vector of length nlam. Giving the size of the active set.}
\item{xbar}{The means of the vectors \code{x, x^2, x^3, ..., x^nbasis}.}
\item{ybar}{The mean of the vector y.}
}
\description{
The main function for univariate non-parametric regression via the
HierBasis estimator.
}
\details{
One of the main functions of the \code{HierBasis} package. This function
fit a univariate nonparametric regression model. This is achieved by
minimizing the following function of \eqn{\beta}:
\deqn{minimize_{\beta} (1/2n)||y - \Psi \beta||^2 + \lambda\Omega_m(\beta) ,}
where \eqn{\beta} is a vector of length \eqn{J = } \code{nbasis}.
The penalty function \eqn{\Omega_m} is given by \deqn{\sum a_{j,m}\beta[j:J],}
where \eqn{\beta[j:J]} is \code{beta[j:J]} for a vector \code{beta}.
Finally, the weights \eqn{a_{j,m}} are given by
\deqn{a_{j,m} = j^m - (j-1)^m,} where \eqn{m} denotes the 'smoothness level'.
For details see Haris et al. (2016).
}
\examples{
require(Matrix)

set.seed(1)

# Generate the points x.
n <- 300
x <- (1:300)/300

# A simple quadratic function.
y1 <- 5 * (x - 0.5)^2
y1dat <- y1 + rnorm(n, sd = 0.1)

# A sine wave example.
y2 <- - sin(10 * x - 4)
y2dat <- y2 + rnorm(n, sd = 0.2)

# An exponential function.
y3 <- exp(- 5 * x + 0.5)
y3dat <- y3 + rnorm(n, sd = 0.2)

poly.fit <- HierBasis(x, y1dat)
sine.fit <- HierBasis(x, y2dat)
exp.fit  <- HierBasis(x, y3dat)

\dontrun{
plot(x, y1dat, type = "p", ylab = "y1")
lines(x, y1, lwd = 2)
lines(x, poly.fit$fitted.values[,30], col = "red", lwd = 2)

plot(x, y2dat, type = "p", ylab = "y1")
lines(x, y2, lwd = 2)
lines(x, sine.fit$fitted.values[,40], col = "red", lwd = 2)

plot(x, y3dat, type = "p", ylab = "y1")
lines(x, y3, lwd = 2)
lines(x, exp.fit$fitted.values[,40], col = "red", lwd = 2)
}

}
\references{
Haris, A., Shojaie, A. and Simon, N. (2016). Nonparametric Regression with
Adaptive Smoothness via a Convex Hierarchical Penalty. Available on request
by authors.
}
\seealso{
\code{\link{predict.HierBasis}}, \code{\link{GetDoF.HierBasis}}
}
\author{
Asad Haris (\email{aharis@uw.edu}),
Ali Shojaie and Noah Simon
}
